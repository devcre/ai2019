{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte'\n",
    "                                % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-patterns-idx3-ubyte'\n",
    "                               % kind)\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "#### Loading the data\n",
    "\n",
    "X_train, y_train = load_mnist('./data', kind='train')\n",
    "X_test, y_test = load_mnist('./data', kind='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data\\\\testall-patterns-idx3-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a10234154d4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mX_testall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'testall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-a10234154d4a>\u001b[0m in \u001b[0;36mload_mnist\u001b[1;34m(path, kind)\u001b[0m\n\u001b[0;32m      5\u001b[0m                                % kind)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimgpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         magic, num, rows, cols = struct.unpack(\">IIII\",\n\u001b[0;32m      9\u001b[0m                                                imgpath.read(16))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data\\\\testall-patterns-idx3-ubyte'"
     ]
    }
   ],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-patterns-idx3-ubyte'\n",
    "                               % kind)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(60000, 784)\n",
    "\n",
    "    return images\n",
    "\n",
    "X_testall = load_mnist('./data', kind='testall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sample_number:\t:60000, column_number:784\n",
      "test_sample_number:\t:10000, column_number:784\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_testall' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-da38adcb64e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_sample_number:\\t:%d, column_number:%d'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_sample_number:\\t:%d, column_number:%d'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'testall_sample_number\\t:%d, column_number:%d'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_testall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_testall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_testall' is not defined"
     ]
    }
   ],
   "source": [
    "print('train_sample_number:\\t:%d, column_number:%d' %(X_train.shape[0], X_train.shape[1]))\n",
    "print('test_sample_number:\\t:%d, column_number:%d' %(X_test.shape[0], X_test.shape[1]))\n",
    "print('testall_sample_number\\t:%d, column_number:%d' %(X_testall.shape[0], X_testall.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "# X_testall=X_testall/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = [\n",
    "    [1,0,-1],\n",
    "    [1,0,-1],\n",
    "    [1,0,-1]\n",
    "]\n",
    "\n",
    "def convolution(X,con):\n",
    "    temp_con = np.zeros((26,26))\n",
    "    for y in range(1,26):\n",
    "        for x in range(1,26):\n",
    "            temp = [\n",
    "                [X[y*28+x-29],X[y*28+x-28],X[y*28+x-27]],\n",
    "                [X[y*28+x-1],X[y*28+x],X[y*28+x+1]],\n",
    "                [X[y*28+x+27],X[y*28+x+28],X[y*28+x+29]]\n",
    "            ]\n",
    "            mul_=np.array(temp)*np.array(con)\n",
    "            sum_=np.sum(mul_)\n",
    "            temp_con[y-1][x-1]=sum_\n",
    "    return temp_con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myClassifier(object):\n",
    "    \n",
    "    def __init__(self, C=1000, eta=0.01, batch_size=60, epochs=200, epsilon=1e-8, shuffle=True, params=None, w=0, b=0):\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.class_num = 0\n",
    "        self.shuffle = shuffle\n",
    "        self.update_count = 0\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "        \n",
    "    def fit(self, X, y, params=None, w=0, b=0, testscore = None, eval_score=None):\n",
    "        \n",
    "        X_num, X_fea = np.shape(X)\n",
    "        self.class_num=len(np.unique(y))\n",
    "        #######################################################\n",
    "        con_X=np.zeros((X_num,X_fea+(26*26)))\n",
    "        \n",
    "        for i in range(X_num):\n",
    "            con_X[i]=np.append(X[i],convolution(X[i],con))\n",
    "        \n",
    "        X=con_X\n",
    "        #######################################################\n",
    "        if params is None:\n",
    "            print('fit params=None')\n",
    "            self.params = {\n",
    "                'w': np.random.randn(X_fea+(26*26), self.class_num),\n",
    "                'b': np.random.randn(1, self.class_num)\n",
    "            }\n",
    "        cnt=1\n",
    "        if eval_score is None:\n",
    "            self.score_val = 0\n",
    "                \n",
    "        for Xi in range(self.epochs):\n",
    "            s_data, s_labels = self.shuffling(X, y)\n",
    "            encoded_y=self.encoding(s_labels)\n",
    "            avg_loss = 0\n",
    "            batch_count = int(X_num / self.batch_size)\n",
    "            for t in range(int(batch_count)):\n",
    "                batch_X, batch_y, bs=self.batching(s_data, encoded_y, t)\n",
    "                batch_X = np.reshape(batch_X, (bs, X_fea+(26*26)))\n",
    "                batch_y = np.reshape(batch_y, (bs, self.class_num))\n",
    "                z = self.net_input(batch_X)\n",
    "                loss = self.hinge_loss(batch_y, z)\n",
    "                self.update_w_b(batch_X, batch_y, z, bs, cnt)\n",
    "                cnt+=1\n",
    "                avg_loss += loss\n",
    "                self.update_count += 1\n",
    "                \n",
    "            prev_score = self.score_val\n",
    "            pres_score = self.score(X, y)\n",
    "            print(\"epochs: \", Xi)\n",
    "            print(\"prev_score: \", prev_score)\n",
    "            print(\"pres_score: \", pres_score,\"\\n\")\n",
    "            if prev_score < pres_score:\n",
    "                self.score_val = pres_score\n",
    "            avg_loss /= batch_count\n",
    "        return self\n",
    "    \n",
    "    def update_w_b(self, batch_X, batch_y, z, bs, cnt):\n",
    "        n = np.shape(batch_X)[1]  # num of features\n",
    "        delta_w = np.zeros(self.params['w'].shape)\n",
    "        delta_b = np.zeros(self.params['b'].shape)\n",
    "        z = np.reshape(z, (bs, self.class_num))\n",
    "        temp = 1 - np.multiply(batch_y, z)\n",
    "        temp[temp <= 0] = 0\n",
    "        temp[temp > 0] = 1\n",
    "        y_temp = np.multiply(batch_y, temp.reshape(bs, self.class_num))\n",
    "        delta_w = -(1 / bs) * np.matmul(batch_X.T, y_temp) + (1 / self.C) * self.params['w']\n",
    "        delta_b = -(1 / bs) * np.sum(y_temp, axis=0)\n",
    "        self.params['w'] = self.params['w'] - (self.eta / (1 + self.epsilon * cnt)) * delta_w\n",
    "        self.params['b'] = self.params['b'] - (self.eta / (1 + self.epsilon * cnt)) * delta_b\n",
    "        \n",
    "        return self.params\n",
    "    \n",
    "    def hinge_loss(self, y, z):\n",
    "        loss = 1 - np.multiply(y, z)\n",
    "        loss[loss < 0] = 0\n",
    "        loss = np.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        z = np.matmul(X, self.params['w']) + self.params['b']\n",
    "        return z\n",
    "\n",
    "    def encoding(self, y):\n",
    "        print(np.shape(y)[0])\n",
    "        encoded_y=-1*np.ones((np.shape(y)[0],self.class_num))\n",
    "        for i in range(np.shape(y)[0]):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "        return encoded_y\n",
    "                \n",
    "    def shuffling(self, X, y):\n",
    "        temp_s=list(zip(X,y))\n",
    "        random.shuffle(temp_s)\n",
    "        X,y=zip(*temp_s)\n",
    "        return X,y\n",
    "    \n",
    "    def batching(self, X, y, t):                         \n",
    "        batch_X = X[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        batch_y = y[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        last_size = min(len(X), (t+1) * self.batch_size) - t * self.batch_size\n",
    "        \n",
    "        return batch_X, batch_y,last_size\n",
    "    \n",
    "    def predict(self, X):\n",
    "        m = np.shape(X)[0]\n",
    "        class_score = self.net_input(X)  # return z\n",
    "        pred = np.argmax(class_score, axis=1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        score = np.mean(pred == y)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'C':self.C, 'batch_size':self.batch_size, 'epochs':self.epochs,\n",
    "               'eta': self.eta, 'w':self.params['w'], 'b':self.params['b']}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def test(self, X, w, b):\n",
    "        z = np.matmul(X, np.array(w)) + np.array(b)\n",
    "        p = np.argmax(z, axis=1)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "60000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d159722cf431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0ms_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mencoded_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-d159722cf431>\u001b[0m in \u001b[0;36mencoding\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mencoded_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mencoded_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "def shuffling(X, y):\n",
    "    temp_s=list(zip(X,y))\n",
    "    random.shuffle(temp_s)\n",
    "    X,y=zip(*temp_s)\n",
    "    return X,y\n",
    "def encoding(y):\n",
    "    print(type(y))\n",
    "    print(np.shape(y)[0])\n",
    "    encoded_y=-1*np.ones((np.shape(y)[0],self.class_num))\n",
    "    for i in range(np.shape(y)[0]):\n",
    "        encoded_y[i,y[i]] = 1\n",
    "    return encoded_y\n",
    "\n",
    "s_data, s_labels = shuffling(X_train, y_train)\n",
    "encoded_y=encoding(s_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1460)\n",
      "fit params=None\n",
      "epochs:  0\n",
      "prev_score:  0\n",
      "pres_score:  0.6412125 \n",
      "\n",
      "epochs:  1\n",
      "prev_score:  0.6412125\n",
      "pres_score:  0.738925 \n",
      "\n",
      "epochs:  2\n",
      "prev_score:  0.738925\n",
      "pres_score:  0.7814625 \n",
      "\n",
      "epochs:  3\n",
      "prev_score:  0.7814625\n",
      "pres_score:  0.80405 \n",
      "\n",
      "epochs:  4\n",
      "prev_score:  0.80405\n",
      "pres_score:  0.819 \n",
      "\n",
      "epochs:  5\n",
      "prev_score:  0.819\n",
      "pres_score:  0.8302 \n",
      "\n",
      "epochs:  6\n",
      "prev_score:  0.8302\n",
      "pres_score:  0.8385125 \n",
      "\n",
      "epochs:  7\n",
      "prev_score:  0.8385125\n",
      "pres_score:  0.8444625 \n",
      "\n",
      "epochs:  8\n",
      "prev_score:  0.8444625\n",
      "pres_score:  0.8492875 \n",
      "\n",
      "epochs:  9\n",
      "prev_score:  0.8492875\n",
      "pres_score:  0.8529625 \n",
      "\n",
      "epochs:  10\n",
      "prev_score:  0.8529625\n",
      "pres_score:  0.856 \n",
      "\n",
      "epochs:  11\n",
      "prev_score:  0.856\n",
      "pres_score:  0.8593625 \n",
      "\n",
      "epochs:  12\n",
      "prev_score:  0.8593625\n",
      "pres_score:  0.862475 \n",
      "\n",
      "epochs:  13\n",
      "prev_score:  0.862475\n",
      "pres_score:  0.8644125 \n",
      "\n",
      "epochs:  14\n",
      "prev_score:  0.8644125\n",
      "pres_score:  0.866875 \n",
      "\n",
      "epochs:  15\n",
      "prev_score:  0.866875\n",
      "pres_score:  0.8685875 \n",
      "\n",
      "epochs:  16\n",
      "prev_score:  0.8685875\n",
      "pres_score:  0.870675 \n",
      "\n",
      "epochs:  17\n",
      "prev_score:  0.870675\n",
      "pres_score:  0.87195 \n",
      "\n",
      "epochs:  18\n",
      "prev_score:  0.87195\n",
      "pres_score:  0.8729625 \n",
      "\n",
      "epochs:  19\n",
      "prev_score:  0.8729625\n",
      "pres_score:  0.8746 \n",
      "\n",
      "epochs:  20\n",
      "prev_score:  0.8746\n",
      "pres_score:  0.875525 \n",
      "\n",
      "epochs:  21\n",
      "prev_score:  0.875525\n",
      "pres_score:  0.8765875 \n",
      "\n",
      "epochs:  22\n",
      "prev_score:  0.8765875\n",
      "pres_score:  0.87825 \n",
      "\n",
      "epochs:  23\n",
      "prev_score:  0.87825\n",
      "pres_score:  0.8782 \n",
      "\n",
      "epochs:  24\n",
      "prev_score:  0.87825\n",
      "pres_score:  0.879975 \n",
      "\n",
      "epochs:  25\n",
      "prev_score:  0.879975\n",
      "pres_score:  0.8812625 \n",
      "\n",
      "epochs:  26\n",
      "prev_score:  0.8812625\n",
      "pres_score:  0.88225 \n",
      "\n",
      "epochs:  27\n",
      "prev_score:  0.88225\n",
      "pres_score:  0.883325 \n",
      "\n",
      "epochs:  28\n",
      "prev_score:  0.883325\n",
      "pres_score:  0.8831 \n",
      "\n",
      "epochs:  29\n",
      "prev_score:  0.883325\n",
      "pres_score:  0.8846625 \n",
      "\n",
      "epochs:  30\n",
      "prev_score:  0.8846625\n",
      "pres_score:  0.8855125 \n",
      "\n",
      "epochs:  31\n",
      "prev_score:  0.8855125\n",
      "pres_score:  0.886675 \n",
      "\n",
      "epochs:  32\n",
      "prev_score:  0.886675\n",
      "pres_score:  0.8868625 \n",
      "\n",
      "epochs:  33\n",
      "prev_score:  0.8868625\n",
      "pres_score:  0.8882625 \n",
      "\n",
      "epochs:  34\n",
      "prev_score:  0.8882625\n",
      "pres_score:  0.8879125 \n",
      "\n",
      "epochs:  35\n",
      "prev_score:  0.8882625\n",
      "pres_score:  0.89015 \n",
      "\n",
      "epochs:  36\n",
      "prev_score:  0.89015\n",
      "pres_score:  0.8904875 \n",
      "\n",
      "epochs:  37\n",
      "prev_score:  0.8904875\n",
      "pres_score:  0.8905625 \n",
      "\n",
      "epochs:  38\n",
      "prev_score:  0.8905625\n",
      "pres_score:  0.891625 \n",
      "\n",
      "epochs:  39\n",
      "prev_score:  0.891625\n",
      "pres_score:  0.893075 \n",
      "\n",
      "epochs:  40\n",
      "prev_score:  0.893075\n",
      "pres_score:  0.89305 \n",
      "\n",
      "epochs:  41\n",
      "prev_score:  0.893075\n",
      "pres_score:  0.89415 \n",
      "\n",
      "epochs:  42\n",
      "prev_score:  0.89415\n",
      "pres_score:  0.8939 \n",
      "\n",
      "epochs:  43\n",
      "prev_score:  0.89415\n",
      "pres_score:  0.8940375 \n",
      "\n",
      "epochs:  44\n",
      "prev_score:  0.89415\n",
      "pres_score:  0.8955625 \n",
      "\n",
      "epochs:  45\n",
      "prev_score:  0.8955625\n",
      "pres_score:  0.894825 \n",
      "\n",
      "epochs:  46\n",
      "prev_score:  0.8955625\n",
      "pres_score:  0.896325 \n",
      "\n",
      "epochs:  47\n",
      "prev_score:  0.896325\n",
      "pres_score:  0.897225 \n",
      "\n",
      "epochs:  48\n",
      "prev_score:  0.897225\n",
      "pres_score:  0.8974 \n",
      "\n",
      "epochs:  49\n",
      "prev_score:  0.8974\n",
      "pres_score:  0.8975625 \n",
      "\n",
      "epochs:  50\n",
      "prev_score:  0.8975625\n",
      "pres_score:  0.8977625 \n",
      "\n",
      "epochs:  51\n",
      "prev_score:  0.8977625\n",
      "pres_score:  0.8984125 \n",
      "\n",
      "epochs:  52\n",
      "prev_score:  0.8984125\n",
      "pres_score:  0.8986375 \n",
      "\n",
      "epochs:  53\n",
      "prev_score:  0.8986375\n",
      "pres_score:  0.899175 \n",
      "\n",
      "epochs:  54\n",
      "prev_score:  0.899175\n",
      "pres_score:  0.8995125 \n",
      "\n",
      "epochs:  55\n",
      "prev_score:  0.8995125\n",
      "pres_score:  0.9001 \n",
      "\n",
      "epochs:  56\n",
      "prev_score:  0.9001\n",
      "pres_score:  0.900175 \n",
      "\n",
      "epochs:  57\n",
      "prev_score:  0.900175\n",
      "pres_score:  0.9007375 \n",
      "\n",
      "epochs:  58\n",
      "prev_score:  0.9007375\n",
      "pres_score:  0.900775 \n",
      "\n",
      "epochs:  59\n",
      "prev_score:  0.900775\n",
      "pres_score:  0.9023375 \n",
      "\n",
      "epochs:  60\n",
      "prev_score:  0.9023375\n",
      "pres_score:  0.901825 \n",
      "\n",
      "epochs:  61\n",
      "prev_score:  0.9023375\n",
      "pres_score:  0.9018625 \n",
      "\n",
      "epochs:  62\n",
      "prev_score:  0.9023375\n",
      "pres_score:  0.902275 \n",
      "\n",
      "epochs:  63\n",
      "prev_score:  0.9023375\n",
      "pres_score:  0.9016 \n",
      "\n",
      "epochs:  64\n",
      "prev_score:  0.9023375\n",
      "pres_score:  0.903175 \n",
      "\n",
      "epochs:  65\n",
      "prev_score:  0.903175\n",
      "pres_score:  0.9028 \n",
      "\n",
      "epochs:  66\n",
      "prev_score:  0.903175\n",
      "pres_score:  0.9030875 \n",
      "\n",
      "epochs:  67\n",
      "prev_score:  0.903175\n",
      "pres_score:  0.903725 \n",
      "\n",
      "epochs:  68\n",
      "prev_score:  0.903725\n",
      "pres_score:  0.903475 \n",
      "\n",
      "epochs:  69\n",
      "prev_score:  0.903725\n",
      "pres_score:  0.9036875 \n",
      "\n",
      "epochs:  70\n",
      "prev_score:  0.903725\n",
      "pres_score:  0.9041875 \n",
      "\n",
      "epochs:  71\n",
      "prev_score:  0.9041875\n",
      "pres_score:  0.904175 \n",
      "\n",
      "epochs:  72\n",
      "prev_score:  0.9041875\n",
      "pres_score:  0.905275 \n",
      "\n",
      "epochs:  73\n",
      "prev_score:  0.905275\n",
      "pres_score:  0.9051625 \n",
      "\n",
      "epochs:  74\n",
      "prev_score:  0.905275\n",
      "pres_score:  0.906 \n",
      "\n",
      "epochs:  75\n",
      "prev_score:  0.906\n",
      "pres_score:  0.9055875 \n",
      "\n",
      "epochs:  76\n",
      "prev_score:  0.906\n",
      "pres_score:  0.904575 \n",
      "\n",
      "epochs:  77\n",
      "prev_score:  0.906\n",
      "pres_score:  0.9060375 \n",
      "\n",
      "epochs:  78\n",
      "prev_score:  0.9060375\n",
      "pres_score:  0.9057625 \n",
      "\n",
      "epochs:  79\n",
      "prev_score:  0.9060375\n",
      "pres_score:  0.9056 \n",
      "\n",
      "epochs:  80\n",
      "prev_score:  0.9060375\n",
      "pres_score:  0.9061 \n",
      "\n",
      "epochs:  81\n",
      "prev_score:  0.9061\n",
      "pres_score:  0.9060125 \n",
      "\n",
      "epochs:  82\n",
      "prev_score:  0.9061\n",
      "pres_score:  0.907275 \n",
      "\n",
      "epochs:  83\n",
      "prev_score:  0.907275\n",
      "pres_score:  0.90565 \n",
      "\n",
      "epochs:  84\n",
      "prev_score:  0.907275\n",
      "pres_score:  0.9070375 \n",
      "\n",
      "epochs:  85\n",
      "prev_score:  0.907275\n",
      "pres_score:  0.908025 \n",
      "\n",
      "epochs:  86\n",
      "prev_score:  0.908025\n",
      "pres_score:  0.907025 \n",
      "\n",
      "epochs:  87\n",
      "prev_score:  0.908025\n",
      "pres_score:  0.907575 \n",
      "\n",
      "epochs:  88\n",
      "prev_score:  0.908025\n",
      "pres_score:  0.9082 \n",
      "\n",
      "epochs:  89\n",
      "prev_score:  0.9082\n",
      "pres_score:  0.9081375 \n",
      "\n",
      "epochs:  90\n",
      "prev_score:  0.9082\n",
      "pres_score:  0.9083125 \n",
      "\n",
      "epochs:  91\n",
      "prev_score:  0.9083125\n",
      "pres_score:  0.907075 \n",
      "\n",
      "epochs:  92\n",
      "prev_score:  0.9083125\n",
      "pres_score:  0.9084875 \n",
      "\n",
      "epochs:  93\n",
      "prev_score:  0.9084875\n",
      "pres_score:  0.9084625 \n",
      "\n",
      "epochs:  94\n",
      "prev_score:  0.9084875\n",
      "pres_score:  0.9077 \n",
      "\n",
      "epochs:  95\n",
      "prev_score:  0.9084875\n",
      "pres_score:  0.908375 \n",
      "\n",
      "epochs:  96\n",
      "prev_score:  0.9084875\n",
      "pres_score:  0.9078625 \n",
      "\n",
      "epochs:  97\n",
      "prev_score:  0.9084875\n",
      "pres_score:  0.9079875 \n",
      "\n",
      "epochs:  98\n",
      "prev_score:  0.9084875\n",
      "pres_score:  0.909175 \n",
      "\n",
      "epochs:  99\n",
      "prev_score:  0.909175\n",
      "pres_score:  0.9091875 \n",
      "\n",
      "epochs:  100\n",
      "prev_score:  0.9091875\n",
      "pres_score:  0.908325 \n",
      "\n",
      "epochs:  101\n",
      "prev_score:  0.9091875\n",
      "pres_score:  0.9077625 \n",
      "\n",
      "epochs:  102\n",
      "prev_score:  0.9091875\n",
      "pres_score:  0.9072125 \n",
      "\n",
      "epochs:  103\n",
      "prev_score:  0.9091875\n",
      "pres_score:  0.9094 \n",
      "\n",
      "epochs:  104\n",
      "prev_score:  0.9094\n",
      "pres_score:  0.9085625 \n",
      "\n",
      "epochs:  105\n",
      "prev_score:  0.9094\n",
      "pres_score:  0.909075 \n",
      "\n",
      "epochs:  106\n",
      "prev_score:  0.9094\n",
      "pres_score:  0.9092 \n",
      "\n",
      "epochs:  107\n",
      "prev_score:  0.9094\n",
      "pres_score:  0.9095125 \n",
      "\n",
      "epochs:  108\n",
      "prev_score:  0.9095125\n",
      "pres_score:  0.9098625 \n",
      "\n",
      "epochs:  109\n",
      "prev_score:  0.9098625\n",
      "pres_score:  0.908825 \n",
      "\n",
      "epochs:  110\n",
      "prev_score:  0.9098625\n",
      "pres_score:  0.9087125 \n",
      "\n",
      "epochs:  111\n",
      "prev_score:  0.9098625\n",
      "pres_score:  0.9091875 \n",
      "\n",
      "epochs:  112\n",
      "prev_score:  0.9098625\n",
      "pres_score:  0.910125 \n",
      "\n",
      "epochs:  113\n",
      "prev_score:  0.910125\n",
      "pres_score:  0.9096875 \n",
      "\n",
      "epochs:  114\n",
      "prev_score:  0.910125\n",
      "pres_score:  0.909425 \n",
      "\n",
      "epochs:  115\n",
      "prev_score:  0.910125\n",
      "pres_score:  0.91055 \n",
      "\n",
      "epochs:  116\n",
      "prev_score:  0.91055\n",
      "pres_score:  0.9093625 \n",
      "\n",
      "epochs:  117\n",
      "prev_score:  0.91055\n",
      "pres_score:  0.9099625 \n",
      "\n",
      "epochs:  118\n",
      "prev_score:  0.91055\n",
      "pres_score:  0.90985 \n",
      "\n",
      "epochs:  119\n",
      "prev_score:  0.91055\n",
      "pres_score:  0.9098375 \n",
      "\n",
      "epochs:  120\n",
      "prev_score:  0.91055\n",
      "pres_score:  0.9105125 \n",
      "\n",
      "epochs:  121\n",
      "prev_score:  0.91055\n",
      "pres_score:  0.9109375 \n",
      "\n",
      "epochs:  122\n",
      "prev_score:  0.9109375\n",
      "pres_score:  0.910675 \n",
      "\n",
      "epochs:  123\n",
      "prev_score:  0.9109375\n",
      "pres_score:  0.909975 \n",
      "\n",
      "epochs:  124\n",
      "prev_score:  0.9109375\n",
      "pres_score:  0.910575 \n",
      "\n",
      "epochs:  125\n",
      "prev_score:  0.9109375\n",
      "pres_score:  0.911175 \n",
      "\n",
      "epochs:  126\n",
      "prev_score:  0.911175\n",
      "pres_score:  0.9112 \n",
      "\n",
      "epochs:  127\n",
      "prev_score:  0.9112\n",
      "pres_score:  0.909625 \n",
      "\n",
      "epochs:  128\n",
      "prev_score:  0.9112\n",
      "pres_score:  0.9107125 \n",
      "\n",
      "epochs:  129\n",
      "prev_score:  0.9112\n",
      "pres_score:  0.9105875 \n",
      "\n",
      "epochs:  130\n",
      "prev_score:  0.9112\n",
      "pres_score:  0.9106 \n",
      "\n",
      "epochs:  131\n",
      "prev_score:  0.9112\n",
      "pres_score:  0.91 \n",
      "\n",
      "epochs:  132\n",
      "prev_score:  0.9112\n",
      "pres_score:  0.911525 \n",
      "\n",
      "epochs:  133\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.911175 \n",
      "\n",
      "epochs:  134\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.910175 \n",
      "\n",
      "epochs:  135\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9110125 \n",
      "\n",
      "epochs:  136\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9100625 \n",
      "\n",
      "epochs:  137\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9109125 \n",
      "\n",
      "epochs:  138\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.91 \n",
      "\n",
      "epochs:  139\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9107125 \n",
      "\n",
      "epochs:  140\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9105125 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  141\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9103875 \n",
      "\n",
      "epochs:  142\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.91095 \n",
      "\n",
      "epochs:  143\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9104 \n",
      "\n",
      "epochs:  144\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9108 \n",
      "\n",
      "epochs:  145\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.910075 \n",
      "\n",
      "epochs:  146\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.910525 \n",
      "\n",
      "epochs:  147\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9111125 \n",
      "\n",
      "epochs:  148\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.910575 \n",
      "\n",
      "epochs:  149\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9102 \n",
      "\n",
      "epochs:  150\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.910225 \n",
      "\n",
      "epochs:  151\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9094 \n",
      "\n",
      "epochs:  152\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.910225 \n",
      "\n",
      "epochs:  153\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9099 \n",
      "\n",
      "epochs:  154\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9103 \n",
      "\n",
      "epochs:  155\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.910175 \n",
      "\n",
      "epochs:  156\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.91125 \n",
      "\n",
      "epochs:  157\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9114125 \n",
      "\n",
      "epochs:  158\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9109 \n",
      "\n",
      "epochs:  159\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9094 \n",
      "\n",
      "epochs:  160\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.91055 \n",
      "\n",
      "epochs:  161\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.910175 \n",
      "\n",
      "epochs:  162\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.91085 \n",
      "\n",
      "epochs:  163\n",
      "prev_score:  0.911525\n",
      "pres_score:  0.9115375 \n",
      "\n",
      "epochs:  164\n",
      "prev_score:  0.9115375\n",
      "pres_score:  0.911275 \n",
      "\n",
      "epochs:  165\n",
      "prev_score:  0.9115375\n",
      "pres_score:  0.9110875 \n",
      "\n",
      "epochs:  166\n",
      "prev_score:  0.9115375\n",
      "pres_score:  0.9114125 \n",
      "\n",
      "epochs:  167\n",
      "prev_score:  0.9115375\n",
      "pres_score:  0.911675 \n",
      "\n",
      "epochs:  168\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.9112625 \n",
      "\n",
      "epochs:  169\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.91045 \n",
      "\n",
      "epochs:  170\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.911 \n",
      "\n",
      "epochs:  171\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.9115875 \n",
      "\n",
      "epochs:  172\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.91105 \n",
      "\n",
      "epochs:  173\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.9114 \n",
      "\n",
      "epochs:  174\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.910975 \n",
      "\n",
      "epochs:  175\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.910925 \n",
      "\n",
      "epochs:  176\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.9107375 \n",
      "\n",
      "epochs:  177\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.91085 \n",
      "\n",
      "epochs:  178\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.9111875 \n",
      "\n",
      "epochs:  179\n",
      "prev_score:  0.911675\n",
      "pres_score:  0.9116875 \n",
      "\n",
      "epochs:  180\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.911275 \n",
      "\n",
      "epochs:  181\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.90985 \n",
      "\n",
      "epochs:  182\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9100625 \n",
      "\n",
      "epochs:  183\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9102 \n",
      "\n",
      "epochs:  184\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.91025 \n",
      "\n",
      "epochs:  185\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9112875 \n",
      "\n",
      "epochs:  186\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9101125 \n",
      "\n",
      "epochs:  187\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.911275 \n",
      "\n",
      "epochs:  188\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9113125 \n",
      "\n",
      "epochs:  189\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9094375 \n",
      "\n",
      "epochs:  190\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9108625 \n",
      "\n",
      "epochs:  191\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.910425 \n",
      "\n",
      "epochs:  192\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.910625 \n",
      "\n",
      "epochs:  193\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.91075 \n",
      "\n",
      "epochs:  194\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9105875 \n",
      "\n",
      "epochs:  195\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.909825 \n",
      "\n",
      "epochs:  196\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.9115375 \n",
      "\n",
      "epochs:  197\n",
      "prev_score:  0.9116875\n",
      "pres_score:  0.911725 \n",
      "\n",
      "epochs:  198\n",
      "prev_score:  0.911725\n",
      "pres_score:  0.91125 \n",
      "\n",
      "epochs:  199\n",
      "prev_score:  0.911725\n",
      "pres_score:  0.91125 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.myClassifier at 0x7fb41a135250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine=myClassifier()\n",
    "mine.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=mine.get_params()['w']\n",
    "b=mine.get_params()['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p=mine.test(X_testall,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file=open('/home/ryu/AI/MyClassifier/prediction.txt','w')\n",
    "for i in range(len(p)):\n",
    "    file.write('%s\\n' %p[i])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
