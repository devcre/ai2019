{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6f995417fccb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import random\n",
    "import cupy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage import interpolation\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,'%s-labels-idx1-ubyte'% kind)\n",
    "    images_path = os.path.join(path,'%s-images-idx3-ubyte'% kind)\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "#### Loading the data\n",
    "\n",
    "X_train, y_train = load_mnist('./data', kind='newtrain')\n",
    "X_test, y_test = load_mnist('./data', kind='mnist-new1k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-patterns-idx3-ubyte'\n",
    "                               % kind)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,dtype=np.uint8).reshape(60000, 784)\n",
    "\n",
    "    return images\n",
    "\n",
    "X_testall = load_mnist('./data', kind='testall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_sample_number:\\t:%d, column_number:%d' %(X_train.shape[0], X_train.shape[1]))\n",
    "print('test_sample_number:\\t:%d, column_number:%d' %(X_test.shape[0], X_test.shape[1]))\n",
    "print('testall_sample_number\\t:%d, column_number:%d' %(X_testall.shape[0], X_testall.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "X_testall=X_testall/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "\n",
    "def moments(image):\n",
    "    c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n",
    "    totalImage = np.sum(image) #sum of pixels\n",
    "    m0 = np.sum(c0*image)/totalImage #mu_x\n",
    "    m1 = np.sum(c1*image)/totalImage #mu_y\n",
    "    m00 = np.sum((c0-m0)**2*image)/totalImage #var(x)\n",
    "    m11 = np.sum((c1-m1)**2*image)/totalImage #var(y)\n",
    "    m01 = np.sum((c0-m0)*(c1-m1)*image)/totalImage #covariance(x,y)\n",
    "    mu_vector = np.array([m0,m1]) # Notice that these are \\mu_x, \\mu_y respectively\n",
    "    covariance_matrix = np.array([[m00,m01],[m01,m11]]) # Do you see a similarity between the covariance matrix\n",
    "    return mu_vector, covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(image):\n",
    "    c,v = moments(image)\n",
    "    alpha = v[0,1]/v[0,0]\n",
    "    affine = np.array([[1,0],[alpha,1]])\n",
    "    ocenter = np.array(image.shape)/2.0\n",
    "    offset = c-np.dot(affine,ocenter)\n",
    "    return interpolation.affine_transform(image,affine,offset=offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskewAll(X):\n",
    "    currents = []\n",
    "    for i in range(len(X)):\n",
    "        currents.append(deskew(X[i].reshape(28,28)).flatten())\n",
    "    return np.array(currents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_deskewed = deskewAll(X_train)\n",
    "X_test_deskewed = deskewAll(X_test)\n",
    "# X_test=deskewAll(X_test)\n",
    "#np.shape(X_train_deskewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f1798b2b5ec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_hog_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfd_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "def calc_hog_features(X, image_shape=(28, 28), pixels_per_cell=(8, 8)):\n",
    "    fd_list = []\n",
    "    for row in X:\n",
    "        img = row.reshape(image_shape)\n",
    "        fd = hog(img, orientations=8, pixels_per_cell=pixels_per_cell, cells_per_block=(1, 1))\n",
    "        fd_list.append(fd)\n",
    "    \n",
    "    return np.array(fd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoged_X_train = calc_hog_features(X_train, pixels_per_cell=(8, 8))\n",
    "hoged_X_test = calc_hog_features(X_test, pixels_per_cell=(8, 8))\n",
    "hoged_X_fea=hoged_X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.hstack((X_train_deskewed, con_X_train, hoged_X_train))#,con_X_train))\n",
    "X_testall=np.hstack((X_testall_deskewed, con_X_testall, hoged_X_testall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenel = [\n",
    "    [1,0,-1],\n",
    "    [1,0,-1],\n",
    "    [1,0,-1]\n",
    "]\n",
    "\n",
    "def convolution(X,kenel):\n",
    "    con_X =np.zeros((X.shape[0],26*26))\n",
    "    for y in range(1,26):\n",
    "        for x in range(1,26):\n",
    "            temp=X[y-1:y+2,x-1:x+2]\n",
    "            mul_=np.dot(temp,kenel)\n",
    "            sum_=np.sum(mul_)\n",
    "            con_X[y-1][x-1]=sum_\n",
    "    return con_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_X_train=convolution(X_train,kenel)\n",
    "con_X_test=convolution(X_test,kenel)\n",
    "con_X_fea=con_X_test.shape[1]\n",
    "#np.shape(con_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myClassifier(object):    \n",
    "    \"\"\"\n",
    "    ovr\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1000, eta=0.01, batch_size=60, epochs=200, epsilon=1e-8, \n",
    "                 shuffle=True, params=None, w=0, b=0):\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.class_num = 0\n",
    "        self.shuffle = shuffle\n",
    "        self.update_count = 0\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "        \n",
    "    def fit(self, X, y, params=None, w=0, b=0, testscore = None, eval_score=None):\n",
    "        X_num, X_fea = np.shape(X)\n",
    "        #X_num, X_fea = cp.shape(X)\n",
    "        self.class_num=len(np.unique(y))\n",
    "        #self.class_num=len(cp.unique(y))\n",
    "        \n",
    "        if params is None:\n",
    "            print('fit params=None')\n",
    "            self.params = {\n",
    "                'w': np.random.randn(X_fea, self.class_num), #(10, 784) 정규분포난수\n",
    "                #'w': c.random.randn(X_fea, self.class_num),\n",
    "                'b': np.random.randn(1, self.class_num),\n",
    "                #'b': cp.random.randn(1, self.class_num),\n",
    "                'w_': np.random.randn(X_fea, self.class_num),\n",
    "                #'w_': cp.random.randn(X_fea, self.class_num),\n",
    "                'b_': np.random.randn(1, self.class_num),\n",
    "                #'b_': cp.random.randn(1, self.class_num),\n",
    "                'tmpw': 0,\n",
    "                'tmpb': 0\n",
    "            }\n",
    "        cnt=1\n",
    "        if eval_score is None:\n",
    "            self.score_val = 0\n",
    "            \n",
    "        for Xi in range(self.epochs):\n",
    "            s_data, s_labels = self.shuffling(X, y)\n",
    "            encoded_y=self.encoding(s_labels)\n",
    "            avg_loss = 0\n",
    "            batch_count = int(X_num / self.batch_size)\n",
    "            for t in range(int(batch_count)):\n",
    "                batch_X, batch_y, bs=self.batching(s_data, encoded_y, t)\n",
    "                batch_X = np.reshape(batch_X, (bs, X_fea))\n",
    "                #batch_X = cp.reshape(batch_X, (bs, X_fea))\n",
    "                batch_y = np.reshape(batch_y, (bs, self.class_num))\n",
    "                #batch_y = cp.reshape(batch_y, (bs, self.class_num))\n",
    "                z = self.net_input(batch_X)\n",
    "                loss = self.hinge_loss(batch_y, z)\n",
    "                self.update_w_b(batch_X, batch_y, z, bs, cnt)\n",
    "                cnt+=1\n",
    "                avg_loss += loss\n",
    "                self.update_count += 1\n",
    "                \n",
    "            self.params['tmpw'] = (cnt * (cnt/(cnt+1)) * \n",
    "                                   self.params['w_'] + (1/(cnt+1))*self.params['w'])\n",
    "            self.params['tmpb'] = (cnt * (cnt/(cnt+1)) * \n",
    "                                   self.params['b_'] + (1/(cnt+1))*self.params['b'])\n",
    "            prev_score = self.score_val\n",
    "            pres_score = self.score(X, y)\n",
    "            print(\"epochs: \", Xi)\n",
    "            print(\"prev_score: \", prev_score)\n",
    "            print(\"pres_score: \", pres_score,\"\\n\")\n",
    "            if prev_score < pres_score:\n",
    "                self.score_val = pres_score\n",
    "            if self.det_weight(X, y, 1) < self.det_weight(X, y): # temp_w, temp_b\n",
    "                self.params['w_'] = self.params['tmpw']\n",
    "                self.params['b_'] = self.params['tmpb']\n",
    "            avg_loss /= batch_count\n",
    "        return self\n",
    "    \n",
    "    def det_weight(self, X, y, aver=0):\n",
    "        if aver:\n",
    "            w1 = self.params['w_']\n",
    "            b1 = self.params['b_']\n",
    "        else:\n",
    "            w1 = self.params['tmpw']\n",
    "            b1 = self.params['tmpb']\n",
    "        temp = np.dot(X, w1) + b1\n",
    "        #temp = cp.dot(X, w1) + b1\n",
    "        \n",
    "        pred = np.argmax(temp, axis=1)\n",
    "        #pred = cp.argmax(temp, axis=1)\n",
    "        sco = np.mean(pred == y)\n",
    "        #sco = cp.mean(pred == y)\n",
    "        return sco\n",
    "    \n",
    "    def update_w_b(self, batch_X, batch_y, z, bs, cnt):\n",
    "        n = np.shape(batch_X)[1]  # num of features\n",
    "        #n = cp.shape(batch_X)[1] \n",
    "        delta_w = np.zeros(self.params['w'].shape)\n",
    "        #delta_w = cp.zeros(self.params['w'].shape)\n",
    "        delta_b = np.zeros(self.params['b'].shape)\n",
    "        #delta_b = cp.zeros(self.params['b'].shape)\n",
    "        z = np.reshape(z, (bs, self.class_num))\n",
    "        #z = cp.reshape(z, (bs, self.class_num))\n",
    "        temp = 1 - np.multiply(batch_y, z)\n",
    "        #temp = 1 - cp.multiply(batch_y, z)\n",
    "        temp[temp <= 0] = 0\n",
    "        temp[temp > 0] = 1\n",
    "        y_temp = np.multiply(batch_y, temp.reshape(bs, self.class_num))\n",
    "        #y_temp = cp.multiply(batch_y, temp.reshape(bs, self.class_num))\n",
    "        delta_w = -(1 / bs) * np.matmul(batch_X.T, y_temp) + (1 / self.C) * self.params['w']\n",
    "        #delta_w = -(1 / bs) * cp.matmul(batch_X.T, y_temp) + (1 / self.C) * self.params['w']\n",
    "        delta_b = -(1 / bs) * np.sum(y_temp, axis=0)\n",
    "        #delta_b = -(1 / bs) * cp.sum(y_temp, axis=0)\n",
    "        self.params['w'] = self.params['w'] - (self.eta / (1 + self.epsilon * cnt)) * delta_w\n",
    "        self.params['b'] = self.params['b'] - (self.eta / (1 + self.epsilon * cnt)) * delta_b\n",
    "        \n",
    "        return self.params\n",
    "    \n",
    "    def hinge_loss(self, y, z):\n",
    "        loss = 1 - np.multiply(y, z)\n",
    "        #loss = 1 - cp.multiply(y, z)\n",
    "        loss[loss < 0] = 0\n",
    "        loss = np.mean(loss)\n",
    "        #loss = cp.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "    def net_input(self, X):  # net_input() = forward_prop(), generate z\n",
    "        z = np.matmul(X, self.params['w']) + self.params['b']\n",
    "        #z = cp.matmul(X, self.params['w']) + self.params['b']\n",
    "        return z\n",
    "\n",
    "    def encoding(self, y):\n",
    "        y_array=np.array(y).reshape(-1,1)\n",
    "\n",
    "        enc=OneHotEncoder()\n",
    "        enc.fit(y_array)\n",
    "        y_enc=enc.transform(y_array).toarray()\n",
    "        \n",
    "        encoded_y=-1*np.ones((np.shape(y_test)[0],10))\n",
    "        \n",
    "        y_enc=y_enc * 2 + encoded_y\n",
    "        \n",
    "        \"\"\"\n",
    "        encoded_y=-1*np.ones((np.shape(y)[0],self.class_num))\n",
    "        #encoded_y=-1*cp.ones((cp.shape(y)[0],self.class_num))\n",
    "        for i in range(np.shape(y)[0]):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "        \"\"\"\n",
    "        return y_enc\n",
    "                \n",
    "    def shuffling(self, X, y):\n",
    "        temp_s=list(zip(X,y))\n",
    "        random.shuffle(temp_s)\n",
    "        X,y=zip(*temp_s)\n",
    "        return X,y\n",
    "    \n",
    "    def batching(self, X, y, t):                         \n",
    "        batch_X = X[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        batch_y = y[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        last_size = min(len(X), (t+1) * self.batch_size) - t * self.batch_size\n",
    "        \n",
    "        return batch_X, batch_y,last_size\n",
    "    \n",
    "    def predict(self, X):\n",
    "        m = np.shape(X)[0]\n",
    "        #m = cp.shape(X)[0]\n",
    "        class_score = self.net_input(X)  # return z\n",
    "        pred = np.argmax(class_score, axis=1)\n",
    "        #pred = cp.argmax(class_score, axis=1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        score = np.mean(pred == y)\n",
    "        #score = cp.mean(pred == y)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'C':self.C, 'batch_size':self.batch_size, 'epochs':self.epochs,\n",
    "               'eta': self.eta, 'w':self.params['w_'], 'b':self.params['b_']}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def test(self, X, w, b):\n",
    "        #z = np.matmul(X, np.array(w)) + np.array(b)\n",
    "        z = cp.matmul(X, cp.array(w)) + cp.array(b)\n",
    "        #p = np.argmax(z, axis=1)\n",
    "        p = cp.argmax(z, axis=1)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine=myClassifier()\n",
    "#mine.fit(X_train, y_train)\n",
    "mine.fit(X_test_deskewed,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
