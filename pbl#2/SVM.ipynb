{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    #C:/Users/exist/Codes/ai2019/pbl%#2/data/\n",
    "    #train-patterns-idx3-ubyte\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte'\n",
    "                                % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-patterns-idx3-ubyte'\n",
    "                               % kind)\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "#### Loading the data\n",
    "\n",
    "X_train, y_train = load_mnist('./data/',\n",
    "                              kind='train')\n",
    "X_test, y_test = load_mnist('./data/',\n",
    "                            kind='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sample_number:\t:60000, column_number:784\n",
      "test_sample_number\t:10000, column_number:784\n"
     ]
    }
   ],
   "source": [
    "print('train_sample_number:\\t:%d, column_number:%d' %(X_train.shape[0], X_train.shape[1]))\n",
    "print('test_sample_number\\t:%d, column_number:%d' %(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SETTING LIMITS OF SETS\n",
    "LIMIT = 50000\n",
    "X_train = X_train[:LIMIT]\n",
    "y_train = y_train[:LIMIT]\n",
    "X_test = X_test[:LIMIT]\n",
    "y_test = y_test[:LIMIT]\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myClassifier(object):    \n",
    "    \"\"\"\n",
    "    ovr\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1000, eta=0.001, batch_size=1, epochs=25, epsilon=1e-8, shuffle=True):\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.class_num = 0\n",
    "        self.shuffle = shuffle\n",
    "        self.update_count = 0\n",
    "        \n",
    "    def fit(self, X, y, params=None, testscore=None):\n",
    "        X_num, X_fea = np.shape(X)\n",
    "        #X_num=60000 X_fea=28*28\n",
    "        self.class_num=len(np.unique(y))\n",
    "        #class_num=10\n",
    "        \n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'aver_w': np.random.randn(self.class_num, X_fea), #(784,10) 정규분포난수\n",
    "                'aver_b': np.random.randn(self.class_num, 1),\n",
    "                'w_': np.random.randn(self.class_num, X_fea),\n",
    "                'b_': np.random.randn(self.class_num, 1)\n",
    "            }\n",
    "            w=self.params['w_']\n",
    "            b=self.params['b_']\n",
    "        \n",
    "        if testscore is None:\n",
    "            self.score_val = 0\n",
    "        \n",
    "        cnt=1\n",
    "        \n",
    "        for Xi in range(self.epochs):\n",
    "            #minibatch training\n",
    "            if self.shuffle:\n",
    "                s_data, s_labels = self.shuffling(X, y)\n",
    "                #s_data[60000][28*28]\n",
    "                #s_labels[60000][1]\n",
    "                \n",
    "                encoded_y=self.encoding(s_labels)\n",
    "                #encoded_y[60000][class_num]\n",
    "        \n",
    "            batch_count=X_num/self.batch_size\n",
    "            \n",
    "            for t in range(int(batch_count)):\n",
    "                ###sgd\n",
    "                batch_X, batch_y, bs=self.batching(s_data, encoded_y, t)\n",
    "                #batch_X[batch_size][784] batch_y[batch_size][class_num] last_size=?\n",
    "                \n",
    "                batch_X=np.reshape(batch_X,(bs,X_fea))\n",
    "                batch_y=np.reshape(batch_y,(bs,self.class_num))\n",
    "                \n",
    "                loss=self.hinge_loss(batch_X, batch_y, w, b)\n",
    "                #loss[batch_size][class_num]\n",
    "                loss=1-loss\n",
    "                \n",
    "                #loss[loss>=0]=1\n",
    "                loss[loss<0]=0\n",
    "                \n",
    "                l_M_y=loss*batch_y\n",
    "                #l_M_y  =loss[bs][class_num] batch_y[bs][class_num]\n",
    "                \n",
    "                delta_w=np.zeros((self.class_num,X_fea))\n",
    "                #delta_w[class_num][28*28]\n",
    "                delta_b=np.zeros((self.class_num,1))\n",
    "                #delta_b[10][1]\n",
    "                \n",
    "                temp_w=np.dot(np.transpose(l_M_y),batch_X)\n",
    "                #temp_w[10][28*28]=batch_X[batch_size][28*28]\n",
    "                delta_w=-(1/bs)*temp_w+(1/self.C)*np.array(w)\n",
    "                #delta_w[10][28*28]=c*temp_w[10][28*28]+c*w[10][28*28]\n",
    "                \n",
    "                temp_b=np.sum(np.transpose(l_M_y),axis=1)\n",
    "                temp_b=np.reshape(temp_b,(self.class_num,1))\n",
    "                #temp_b[class_num][1]\n",
    "                delta_b=-(1/bs) * temp_b\n",
    "                #delta_b[10][1]=c*[class_num][1]\n",
    "                cnt+=1\n",
    "                \n",
    "                ###algorism\n",
    "                self.update_count += 1\n",
    "                \n",
    "                w=w-(self.eta*delta_w)\n",
    "                #w[class_num][28*28]\n",
    "                b=np.subtract(b,(self.eta * delta_b))\n",
    "                #b[class_num][1]\n",
    "                \n",
    "            \n",
    "#             temp2_w=cnt * self.params['aver_w'] + np.array(w)\n",
    "#             temp2_w=temp2_w/(cnt+1)\n",
    "#             temp2_b=cnt * self.params['aver_b'] + np.array(b)\n",
    "#             temp2_b=temp2_b/(cnt+1)\n",
    "            \n",
    "            temp2_w=cnt * (cnt/(cnt+1))*self.params['aver_w'] + (1/(cnt+1))*np.array(w)\n",
    "            temp2_b=cnt * (cnt/(cnt+1))*self.params['aver_b'] + (1/(cnt+1))*np.array(b)\n",
    "            \n",
    "            if self.det_weight(X, y, self.params['aver_w'], self.params['aver_b']) < self.det_weight(X, y, temp2_w, temp2_b):\n",
    "                self.params['aver_w'] = temp2_w\n",
    "                self.params['aver_b'] = temp2_b\n",
    "            #self.params['aver_w']=np.where(self.params['aver_w']>temp2_w,self.params['aver_w'],temp2_w)\n",
    "            #self.params['aver_b']=np.where(self.params['aver_b']>temp2_b,self.params['aver_b'],temp2_b)\n",
    "            \n",
    "            prev_score = self.score_val\n",
    "            pres_score = self.score(X, y)\n",
    "            print(\"epoch: \", Xi)\n",
    "            print(\"prev_score: %d\", prev_score)\n",
    "            print(\"pres_score: %d\", pres_score)\n",
    "#             print(\"aver_w: %d\\n\", self.params['aver_w'], \" w_: %d\", self.params['w_'])\n",
    "#             print(\"aver_b: %d\\n\", self.params['aver_b'], \" b_: %d\", self.params['b_'])\n",
    "            print('\\n')\n",
    "            if prev_score < pres_score:\n",
    "                self.score_val = pres_score\n",
    "                self.params['w_'] = w\n",
    "                self.params['b_'] = b\n",
    "        #return w, b\n",
    "        return self.params['w_'], self.params['b_']#self.params['aver_w'], self.params['aver_b']\n",
    "        \n",
    "    def encoding(self, y):\n",
    "        encoded_y=-1*np.ones((np.shape(y)[0],self.class_num))\n",
    "        #encoded_y[60000][class_num]\n",
    "        for i in range(np.shape(y)[0]):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "        return encoded_y\n",
    "                \n",
    "    def shuffling(self, X, y):\n",
    "        temp_s=list(zip(X,y))\n",
    "        random.shuffle(temp_s)\n",
    "        X,y=zip(*temp_s)\n",
    "        return X,y\n",
    "    \n",
    "    def batching(self, X, y, t):                         \n",
    "        batch_X=X[t*self.batch_size:min(len(X),(t+1)*self.batch_size)]\n",
    "        #batch_X[batch_size][28*28]\n",
    "        batch_y=y[t*self.batch_size:min(len(X),(t+1)*self.batch_size)]\n",
    "        #batch_y[batch_size][class_num]\n",
    "        last_size=min(len(X), (t+1)*self.batch_size)-t*self.batch_size\n",
    "        #last_size[size][28*28]\n",
    "        \n",
    "        return batch_X, batch_y,last_size\n",
    "    \n",
    "    def hinge_loss(self, X, y, w, b):\n",
    "        net_v=self.net_input(X,w)\n",
    "        #net_v[batch_size][class_num]\n",
    "        temp_l=np.array(net_v)+np.transpose(b)\n",
    "        #temp_l[batch_size][class_num]\n",
    "        loss=y*temp_l\n",
    "        #loss[batch_size][class_num]\n",
    "        return loss\n",
    "    \n",
    "    def net_input(self, X, w):\n",
    "        #X[batch_size][28*28] w[class_num][28*28]\n",
    "        net=np.dot(X,np.transpose(w))\n",
    "        #[batch_size][class_num]\n",
    "        return net\n",
    "    \n",
    "    def test(self,X,y,w,b):\n",
    "        cor = 0\n",
    "        err = 0\n",
    "        net_v=self.net_input(X,w)\n",
    "        #net_v[batch_size][class_num]\n",
    "        temp_t=np.add(net_v,np.transpose(b))\n",
    "        #temp_t[batch_size][class_num]\n",
    "        p=np.argmax(temp_t,axis=1)\n",
    "        score = np.mean(p == y)\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            c = np.argmax(temp_t, axis=1)[i]\n",
    "            if c == y[i]:\n",
    "                cor += 1\n",
    "            else:\n",
    "                err += 1\n",
    "        return score, cor, err\n",
    "    \n",
    "    def predict(self, X):\n",
    "        w_=self.params['w_']\n",
    "        b_=self.params['b_']\n",
    "        cla_score = self.net_input(w_, X)\n",
    "        temp=np.add(cla_score,b_)\n",
    "        temp = temp.T\n",
    "        pred = np.argmax(temp, axis=1)\n",
    "        return pred\n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "#         w_ = np.reshape(w_, (10,784))\n",
    "#         b_ = np.reshape(b_, (10,1))\n",
    "        pred = self.predict(X)\n",
    "        score = np.mean(pred == y_true)\n",
    "        \n",
    "        return score\n",
    "    def det_weight(self, X, y, w1, b1):\n",
    "        cla_score = self.net_input(w1, X)\n",
    "        temp = np.add(cla_score, b1)\n",
    "        temp = temp.T\n",
    "        pred = np.argmax(temp, axis=1)\n",
    "        sco = np.mean(pred == y)\n",
    "        \n",
    "        return sco\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'C':self.C, 'batch_size':self.batch_size, 'epochs':self.epochs}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-671b057e0e48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-5e11f3a4553d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, params, testscore)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;31m#delta_b[10][1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mtemp_w\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_M_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[1;31m#temp_w[10][28*28]=batch_X[batch_size][28*28]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0mdelta_w\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtemp_w\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mine=myClassifier()\n",
    "w,b=mine.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.shape)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = mine.score(X_train, y_train)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, cor, err = mine.test(X_train, y_train, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)\n",
    "print(cor)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV with Customized mode SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'C':[0.01, 0.1, 1, 10, 100, 1000],\n",
    "#     'C':[0.01, 0.1, 1, 10, 100, 1000, 3000]\n",
    "#     'batch_size':[1, 10, 60, 100, 600]\n",
    "     'epochs':[5, 10, 25, 50, 200]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(myClassifier(), param_grid=params, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = cv.predict(X_train)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco = cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "scoring = {'f1 macro': make_scorer(f1_score , average='macro'), 'f1 micro': make_scorer(f1_score, average = 'micro'), 'Accuracy': make_scorer(accuracy_score) }\n",
    "\n",
    "svm_grid = GridSearchCV(myClassifier(), params, cv=3, scoring=scoring, refit=False, n_jobs=-1)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "svmcv_result = pd.DataFrame(svm_grid.cv_results_)\n",
    "svmcv_result.to_csv(\"svmcv_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
