{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\dm2019\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "## loading mnist dataset\n",
    "\n",
    "raw_train = read_idx(\"./data/train-patterns-idx3-ubyte\")\n",
    "train_data = np.reshape(raw_train, (60000, 28*28))\n",
    "train_label = read_idx(\"./data/train-labels-idx1-ubyte\")\n",
    "\n",
    "raw_test = read_idx(\"./data/mnist-new1k-images-idx3-ubyte\")\n",
    "test_data = np.reshape(raw_test, (10000, 28*28))\n",
    "test_label = read_idx(\"./data/mnist-new1k-labels-idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' input\\n    argv : PATH\\n    eg) python team1.py ./data/newtrain-images-idx3-ubyte ./data/newtrain-labels-idx1-ubyte ./data/mnist_new_testall-patterns-idx3-ubyte\\n    for test : team1.py ./data/train-patterns-idx3-ubyte ./data/train-labels-idx1-ubyte ./data/test-patterns-idx3-ubyte ./data/test-labels-idx1-ubyte\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import struct\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "class myClassifier(object):\n",
    "    \"\"\"\n",
    "    ovr\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1000, eta=0.1, batch_size=20, epochs=100, epsilon=1e-8, \n",
    "                 shuffle=True, params=None, w=0, b=0):\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.class_num = 0\n",
    "        self.shuffle = shuffle\n",
    "        self.update_count = 0\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "#         self.params['aver_w'] = w\n",
    "#         self.params['aver_b'] = b\n",
    "        \n",
    "    def fit(self, X, y, params=None, w=0, b=0, testscore = None, eval_score=None):\n",
    "        # X_num = m, X_fea = n\n",
    "        # m = np.shape(X)[0], n = np.shape(X)[1]\n",
    "        \n",
    "        X_num, X_fea = np.shape(X)\n",
    "        #X_num=60000 X_fea=28*28\n",
    "        self.class_num=len(np.unique(y))\n",
    "        #class_num=10\n",
    "        \n",
    "        if params is None:\n",
    "            print('fit params=None')\n",
    "            self.params = {\n",
    "                'w': np.random.randn(X_fea, self.class_num), #(10, 784) 정규분포난수\n",
    "                'b': np.random.randn(1, self.class_num),\n",
    "                'w_': np.random.randn(X_fea, self.class_num),\n",
    "                'b_': np.random.randn(1, self.class_num),\n",
    "                'tmpw': 0,\n",
    "                'tmpb': 0\n",
    "            }\n",
    "        cnt=1\n",
    "        if eval_score is None:\n",
    "            self.score_val = 0\n",
    "                \n",
    "        for Xi in range(self.epochs):\n",
    "            s_data, s_labels = self.shuffling(X, y)\n",
    "            encoded_y=self.encoding(s_labels)\n",
    "            avg_loss = 0\n",
    "            batch_count = int(X_num / self.batch_size)\n",
    "            for t in range(int(batch_count)):\n",
    "#                self.params['tmpw'] = temp_w, self.params['tmpb'] = temp_b\n",
    "                batch_X, batch_y, bs=self.batching(s_data, encoded_y, t)\n",
    "                batch_X = np.reshape(batch_X, (bs, X_fea))\n",
    "                batch_y = np.reshape(batch_y, (bs, self.class_num))\n",
    "                z = self.net_input(batch_X)\n",
    "                loss = self.hinge_loss(batch_y, z)\n",
    "                self.update_w_b(batch_X, batch_y, z, bs, cnt)\n",
    "                cnt+=1\n",
    "                avg_loss += loss\n",
    "                self.update_count += 1\n",
    "\n",
    "            self.params['tmpw'] = (cnt * (cnt/(cnt+1)) * \n",
    "                                   self.params['w_'] + (1/(cnt+1))*self.params['w'])\n",
    "            self.params['tmpb'] = (cnt * (cnt/(cnt+1)) * \n",
    "                                   self.params['b_'] + (1/(cnt+1))*self.params['b'])\n",
    "            prev_score = self.score_val\n",
    "            pres_score = self.score(X, y)\n",
    "            if Xi % 10 == 0:\n",
    "                print(\"epochs: \", Xi)\n",
    "                print(\"prev_score: \", prev_score)\n",
    "                print(\"pres_score: \", pres_score)\n",
    "                print()\n",
    "            if prev_score < pres_score:\n",
    "                self.score_val = pres_score\n",
    "            if self.det_weight(X, y, 1) < self.det_weight(X, y): # temp_w, temp_b\n",
    "                self.params['w_'] = self.params['tmpw']\n",
    "                self.params['b_'] = self.params['tmpb']\n",
    "            avg_loss /= batch_count\n",
    "        return self\n",
    "    \n",
    "    def det_weight(self, X, y, aver=0):\n",
    "        if aver:\n",
    "            w1 = self.params['w_']\n",
    "            b1 = self.params['b_']\n",
    "        else:\n",
    "            w1 = self.params['tmpw']\n",
    "            b1 = self.params['tmpb']\n",
    "        temp = np.dot(X, w1) + b1\n",
    "#         temp = temp.T\n",
    "        pred = np.argmax(temp, axis=1)\n",
    "        sco = np.mean(pred == y)\n",
    "        return sco\n",
    "    \n",
    "    def update_w_b(self, batch_X, batch_y, z, bs, cnt):\n",
    "        n = np.shape(batch_X)[1]  # num of features\n",
    "        delta_w = np.zeros(self.params['w'].shape)\n",
    "        delta_b = np.zeros(self.params['b'].shape)\n",
    "        z = np.reshape(z, (bs, self.class_num))\n",
    "        temp = 1 - np.multiply(batch_y, z)\n",
    "        temp[temp <= 0] = 0\n",
    "        temp[temp > 0] = 1\n",
    "        y_temp = np.multiply(batch_y, temp.reshape(bs, self.class_num))\n",
    "        delta_w = -(1 / bs) * np.matmul(batch_X.T, y_temp) + (1 / self.C) * self.params['w']\n",
    "        delta_b = -(1 / bs) * np.sum(y_temp, axis=0)\n",
    "        self.params['w'] = self.params['w'] - (self.eta / (1 + self.epsilon * cnt)) * delta_w\n",
    "        self.params['b'] = self.params['b'] - (self.eta / (1 + self.epsilon * cnt)) * delta_b\n",
    "        \n",
    "        return self.params\n",
    "    \n",
    "    def hinge_loss(self, y, z):\n",
    "        loss = 1 - np.multiply(y, z)\n",
    "        loss[loss < 0] = 0\n",
    "        loss = np.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "    def net_input(self, X):  # net_input() = forward_prop(), generate z\n",
    "        z = np.matmul(X, self.params['w']) + self.params['b']\n",
    "        return z\n",
    "\n",
    "    def encoding(self, y):\n",
    "        encoded_y=-1*np.ones((np.shape(y)[0],self.class_num))\n",
    "        for i in range(np.shape(y)[0]):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "        return encoded_y\n",
    "\n",
    "    def shuffling(self, X, y):\n",
    "        temp_s=list(zip(X,y))\n",
    "        random.shuffle(temp_s)\n",
    "        X,y=zip(*temp_s)\n",
    "        return X,y\n",
    "\n",
    "    def batching(self, X, y, t):                         \n",
    "        batch_X = X[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        batch_y = y[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        last_size = min(len(X), (t+1) * self.batch_size) - t * self.batch_size\n",
    "        \n",
    "        return batch_X, batch_y,last_size\n",
    "    \n",
    "    def predict(self, X):\n",
    "        m = np.shape(X)[0]\n",
    "        class_score = self.net_input(X)  # return z\n",
    "        pred = np.argmax(class_score, axis=1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        score = np.mean(pred == y)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'C':self.C, 'batch_size':self.batch_size, 'epochs':self.epochs,\n",
    "               'eta': self.eta, 'w':self.params['w'], 'b':self.params['b']}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def test(self, X, w, b):\n",
    "        print(\"============== TESTING =================\")\n",
    "        z = np.dot(X, np.array(w)) + np.array(b)\n",
    "        p = np.argmax(z, axis=1)\n",
    "        return p\n",
    "\n",
    "def main(training_image, training_label, test_image, test_label=None):\n",
    "    ## loading mnist dataset ##\n",
    "    # raw_train = read_idx(training_image)\n",
    "    # train_data = np.reshape(raw_train, (80000, 28*28))\n",
    "    # train_label = read_idx(training_label)\n",
    "\n",
    "    # raw_test = read_idx(test_image)\n",
    "    # test_data = np.reshape(raw_test, (60000, 28*28))\n",
    "    # ## test_label = read_idx(\"./data/test-labels-idx1-ubyte\")\n",
    "\n",
    "    ## For Testing Score\n",
    "    raw_train = read_idx(training_image)\n",
    "    train_data = np.reshape(raw_train, (60000, 28*28))\n",
    "    train_label = read_idx(training_label)\n",
    "\n",
    "    raw_test = read_idx(test_image)\n",
    "    test_data = np.reshape(raw_test, (10000, 28*28))\n",
    "    test_label = read_idx(training_label)\n",
    "\n",
    "    ## Standardzation ##\n",
    "    # X_train_std = StandardScaler().fit_transform(train_data)\n",
    "    # X_test_std = StandardScaler().fit_transform(test_data)\n",
    "    X_train_std = train_data / 255\n",
    "    X_test_std = test_data / 255\n",
    "\n",
    "    ## SVM model ##\n",
    "    mysvm = myClassifier(C=1000, batch_size=20, epochs=200, eta= 0.01).fit(X_train_std, train_label)\n",
    "\n",
    "    w = mysvm.get_params()['w']\n",
    "    b = mysvm.get_params()['b']\n",
    "\n",
    "    pred = mysvm.test(X_test_std, w, b)\n",
    "\n",
    "    cor_sco = 0\n",
    "    err_sco = 0\n",
    "    cnt = 0\n",
    "    k = 0\n",
    "    for val in pred:\n",
    "        if val == test_label[k]:\n",
    "            cor_sco += 1\n",
    "        else:\n",
    "            err_sco += 1\n",
    "        k += 1\n",
    "        cnt += 1\n",
    "    \n",
    "    print(\"Correction Score: \", cor_sco)\n",
    "    print(\"Error Score: \", err_sco)\n",
    "\n",
    "    acc_sco = accuracy_score(test_label, pred)\n",
    "\n",
    "    file=open('./prediction.txt','w')\n",
    "    for i in range(len(pred)):\n",
    "        file.write('%s\\n' %pred[i])\n",
    "    file.close()\n",
    "\n",
    "\"\"\" input\n",
    "    argv : PATH\n",
    "    eg) python team1.py ./data/newtrain-images-idx3-ubyte ./data/newtrain-labels-idx1-ubyte ./data/mnist_new_testall-patterns-idx3-ubyte\n",
    "    for test : team1.py ./data/train-patterns-idx3-ubyte ./data/train-labels-idx1-ubyte ./data/test-patterns-idx3-ubyte ./data/test-labels-idx1-ubyte\n",
    "\"\"\"\n",
    "# if __name__ == \"__main__\":\n",
    "#     main(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = train_data / 255\n",
    "X_test_std = test_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit params=None\n",
      "epochs:  0\n",
      "prev_score:  0\n",
      "pres_score:  0.6031333333333333\n",
      "\n",
      "epochs:  10\n",
      "prev_score:  0.8012166666666667\n",
      "pres_score:  0.8066666666666666\n",
      "\n",
      "epochs:  20\n",
      "prev_score:  0.8348\n",
      "pres_score:  0.8367333333333333\n",
      "\n",
      "epochs:  30\n",
      "prev_score:  0.8487\n",
      "pres_score:  0.85005\n",
      "\n",
      "epochs:  40\n",
      "prev_score:  0.8582333333333333\n",
      "pres_score:  0.8553333333333333\n",
      "\n",
      "epochs:  50\n",
      "prev_score:  0.8605166666666667\n",
      "pres_score:  0.8616\n",
      "\n",
      "epochs:  60\n",
      "prev_score:  0.8617333333333334\n",
      "pres_score:  0.8606166666666667\n",
      "\n",
      "epochs:  70\n",
      "prev_score:  0.8625666666666667\n",
      "pres_score:  0.8602333333333333\n",
      "\n",
      "epochs:  80\n",
      "prev_score:  0.8625666666666667\n",
      "pres_score:  0.8610666666666666\n",
      "\n",
      "epochs:  90\n",
      "prev_score:  0.8625666666666667\n",
      "pres_score:  0.8611833333333333\n",
      "\n",
      "epochs:  100\n",
      "prev_score:  0.8625666666666667\n",
      "pres_score:  0.8608333333333333\n",
      "\n",
      "epochs:  110\n",
      "prev_score:  0.8625666666666667\n",
      "pres_score:  0.8617666666666667\n",
      "\n",
      "epochs:  120\n",
      "prev_score:  0.8625666666666667\n",
      "pres_score:  0.8626333333333334\n",
      "\n",
      "epochs:  130\n",
      "prev_score:  0.8626333333333334\n",
      "pres_score:  0.8619666666666667\n",
      "\n",
      "epochs:  140\n",
      "prev_score:  0.8626333333333334\n",
      "pres_score:  0.8623166666666666\n",
      "\n",
      "epochs:  150\n",
      "prev_score:  0.8626333333333334\n",
      "pres_score:  0.86085\n",
      "\n",
      "epochs:  160\n",
      "prev_score:  0.8626333333333334\n",
      "pres_score:  0.86075\n",
      "\n",
      "epochs:  170\n",
      "prev_score:  0.8632166666666666\n",
      "pres_score:  0.8602\n",
      "\n",
      "epochs:  180\n",
      "prev_score:  0.8632166666666666\n",
      "pres_score:  0.8619666666666667\n",
      "\n",
      "epochs:  190\n",
      "prev_score:  0.8632166666666666\n",
      "pres_score:  0.86165\n",
      "\n",
      "============== TESTING =================\n",
      "Correction Score:  8598\n",
      "Error Score:  1402\n",
      "0.8598\n"
     ]
    }
   ],
   "source": [
    "mysvm = myClassifier(C=1000, batch_size=20, epochs=200, eta= 0.01).fit(X_train_std, train_label)\n",
    "\n",
    "w = mysvm.get_params()['w']\n",
    "b = mysvm.get_params()['b']\n",
    "\n",
    "pred = mysvm.test(X_test_std, w, b)\n",
    "\n",
    "cor_sco = 0\n",
    "err_sco = 0\n",
    "cnt = 0\n",
    "k = 0\n",
    "for val in pred:\n",
    "    if val == test_label[k]:\n",
    "        cor_sco += 1\n",
    "    else:\n",
    "        err_sco += 1\n",
    "    k += 1\n",
    "    cnt += 1\n",
    "\n",
    "print(\"Correction Score: \", cor_sco)\n",
    "print(\"Error Score: \", err_sco)\n",
    "\n",
    "acc_sco = accuracy_score(test_label, pred)\n",
    "print(acc_sco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
